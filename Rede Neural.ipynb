{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras import optimizers\n",
    "import pylab\n",
    "import pydicom as dicom\n",
    "import glob\n",
    "import png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificação dos caminhos dos diretório com imagens de treinamento e de validação\n",
    "\n",
    "training_data = 'imagens/treinamento'\n",
    "validation_data = 'imagens/validacao'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformação das imagens DICOM em PNG\n",
    "\n",
    "diretorio_list = ['imagens/treinamento/positivo/', 'imagens/validacao/positivo/',\n",
    "                  'imagens/treinamento/negativo/', 'imagens/validacao/negativo/', 'imagens/teste/']\n",
    "for diretorio in diretorio_list:\n",
    "    for img in glob.glob(diretorio + '*.dcm'):\n",
    "        ImageFile = dicom.read_file(img) \n",
    "        png_nome = os.path.basename(img)[:-3] + 'png'\n",
    "        pylab.imsave(diretorio+png_nome, ImageFile.pixel_array, cmap=pylab.cm.bone)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geração das classes das imagens de treinamento e de validação\n",
    "\n",
    "img_width, img_height = 512, 512\n",
    "\n",
    "# used to rescale the pixel values from [0, 255] to [0, 1] interval\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        training_data,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=16,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        validation_data,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construção do modelo para a rede neural\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Primeira camada convolucional\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(img_width, img_height,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Segunda camada convolucional\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Terceira camada convolucional\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flattening\n",
    "model.add(Flatten())\n",
    "\n",
    "# Full connection\n",
    "model.add(Dense(units = 128, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento e validação da rede\n",
    "\n",
    "nb_epoch  = 40\n",
    "nb_train_samples = 178\n",
    "nb_validation_samples = 89\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=nb_train_samples,\n",
    "        nb_epoch=nb_epoch,\n",
    "        validation_data=validation_generator,\n",
    "        nb_val_samples=nb_validation_samples)\n",
    "model.save_weights('modelos/basic_cnn_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste\n",
    "\n",
    "diretorio = 'imagens/teste/'\n",
    "for img_path in glob.glob(diretorio + '*.png'):\n",
    "    if '.png' in img_path:\n",
    "        img = image.load_img(img_path, target_size=(512, 512))\n",
    "\n",
    "        img_teste = image.img_to_array(img)\n",
    "        img_teste = np.expand_dims(img_teste, axis=0) * 1./255\n",
    "\n",
    "        nome_arquivo = os.path.basename(img_path)\n",
    "        score = model.predict(img_teste)\n",
    "        \n",
    "        if score > 0.5:\n",
    "            predicao = 'Com pólipo'\n",
    "        else:\n",
    "            predicao = 'Sem pólipo'\n",
    "            \n",
    "        print('ARQUIVO: ', nome_arquivo)\n",
    "        print('Predição: ', predicao)\n",
    "        print('Score: ', ': ', score, '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
