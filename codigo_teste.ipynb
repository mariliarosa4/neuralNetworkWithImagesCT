{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = 'imagens/treinamento'\n",
    "validation_data = 'imagens/validacao'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000008.png\n",
      "000007.png\n",
      "000006.png\n",
      "000005.png\n",
      "000004.png\n",
      "000002.png\n",
      "000003.png\n",
      "000000.png\n",
      "000001.png\n"
     ]
    }
   ],
   "source": [
    "import pylab\n",
    "import pydicom as dicom\n",
    "import glob\n",
    "import png\n",
    "import os\n",
    "\n",
    "#Transforma as imagens DICOM em PNG\n",
    "\n",
    "diretorio_list = ['imagens/treinamento/positivo/', 'imagens/validacao/positivo/',\n",
    "                  'imagens/treinamento/negativo/', 'imagens/validacao/negativo/']\n",
    "for diretorio in diretorio_list:\n",
    "    for img in glob.glob(diretorio + '*.dcm'):\n",
    "          mri_file = open(img, 'rb')\n",
    "          imagem = dicom.read_file(mri_file)\n",
    "          mri_file.close()\n",
    "\n",
    "          shape = imagem.pixel_array.shape\n",
    "\n",
    "          image_2d = []\n",
    "          max_val = 0\n",
    "          for row in imagem.pixel_array:\n",
    "              pixels = []\n",
    "              for col in row:\n",
    "                  pixels.append(col)\n",
    "                  if col > max_val: max_val = col\n",
    "              image_2d.append(pixels)\n",
    "\n",
    "          image_2d_scaled = []\n",
    "          for row in image_2d:\n",
    "              row_scaled = []\n",
    "              for col in row:\n",
    "                  col_scaled = int((float(col) / float(max_val)) * 255.0)\n",
    "                  row_scaled.append(col_scaled)\n",
    "              image_2d_scaled.append(row_scaled)\n",
    "\n",
    "          png_nome = os.path.basename(img)[:-3] + 'png'\n",
    "          print(png_nome)\n",
    "          png_file = open(diretorio+png_nome, 'wb')\n",
    "          w = png.Writer(shape[1], shape[0], greyscale=True)\n",
    "          w.write(png_file, image_2d_scaled)\n",
    "          png_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 images belonging to 2 classes.\n",
      "Found 4 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "img_width, img_height = 512, 512\n",
    "\n",
    "# used to rescale the pixel values from [0, 255] to [0, 1] interval\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# automagically retrieve images and their classes for train and validation sets\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        training_data,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=16,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        validation_data,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriela/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(512, 512,...)`\n",
      "  \n",
      "/home/gabriela/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "  del sys.path[0]\n",
      "/home/gabriela/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3))`\n"
     ]
    }
   ],
   "source": [
    "#Construindo o modelo \n",
    "# Initialising the CNN\n",
    "model = Sequential()\n",
    "\n",
    "# Convolution\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(img_width, img_height,3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second convolutional layer\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#Terceira camada\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flattening\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "# Full connection\n",
    "model.add(Dense(units = 128, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriela/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  if sys.path[0] == '':\n",
      "/home/gabriela/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=<keras_pre..., steps_per_epoch=5, epochs=10, validation_steps=50)`\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 32s 6s/step - loss: 5.2397 - acc: 0.6000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 28s 6s/step - loss: 6.3770 - acc: 0.6000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 29s 6s/step - loss: 6.3770 - acc: 0.6000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 29s 6s/step - loss: 3.4329 - acc: 0.6400 - val_loss: 1.4052 - val_acc: 0.5000\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 34s 7s/step - loss: 1.2517 - acc: 0.5600 - val_loss: 0.5883 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 31s 6s/step - loss: 0.4611 - acc: 0.6400 - val_loss: 0.5141 - val_acc: 0.7500\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.2392 - acc: 0.9600 - val_loss: 0.3501 - val_acc: 0.7500\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.0746 - acc: 1.0000 - val_loss: 0.6694 - val_acc: 0.7500\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 29s 6s/step - loss: 0.0289 - acc: 1.0000 - val_loss: 1.1244 - val_acc: 0.7500\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 30s 6s/step - loss: 0.0834 - acc: 0.9600 - val_loss: 0.7406 - val_acc: 0.7500\n"
     ]
    }
   ],
   "source": [
    "#Treinamento\n",
    "\n",
    "nb_epoch  = 10\n",
    "nb_train_samples = 90\n",
    "nb_validation_samples = 50\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=nb_train_samples,\n",
    "        nb_epoch=nb_epoch,\n",
    "        validation_data=validation_generator,\n",
    "        nb_val_samples=nb_validation_samples)\n",
    "model.save_weights('modelos/basic_cnn_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01493564]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "#Teste\n",
    "img = image.load_img('imagens/teste/000003.png', target_size=(512, 512))\n",
    "\n",
    "img_teste = image.img_to_array(img)\n",
    "img_teste = np.expand_dims(img_teste, axis=0) * 1./255\n",
    "#score = model.predict(x)\n",
    "\n",
    "prediction = model.predict(img_teste)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
